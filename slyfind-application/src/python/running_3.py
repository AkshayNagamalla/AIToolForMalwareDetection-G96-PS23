import subprocess
import time
import os
import pandas as pd
import pickle  # Assuming your model is saved using joblib
import warnings
import sys
# Set warnings to be ignored (filter out all warnings)
warnings.filterwarnings("ignore")


# def start_capture(duration, output_file):
#     # Start Wireshark capture in the backgro
#     capture_cmd = ["tshark", "-i", "Wi-Fi", "-a",
#                    "duration:" + str(duration), "-w", output_file]
#     print("Executing capture command:", ' '.join(capture_cmd))
#     subprocess.Popen(capture_cmd, stdout=subprocess.PIPE,
#                      stderr=subprocess.PIPE)


# def send_to_cicflowmeter(input_file, output_directory):
#     os.chdir("./bin")
#     # Run Docker container with CICFlowMeter
#     cicflowmeter_cmd = [
#         "cfm.bat", input_file, output_directory
#     ]
#     print("Executing CICFlowMeter command:", ' '.join(cicflowmeter_cmd))
#     subprocess.run(cicflowmeter_cmd)


def process_flow_csv(flow_csv_path):
    # Read the CSV file into a DataFrame
    df = pd.read_csv(flow_csv_path)

    # Apply desired column drops
    df = df.drop(columns=['Flow ID', 'Src IP', 'Src Port',
                 'Dst IP', 'Protocol', 'Timestamp'])
    df = df.drop(columns=['Dst Port', 'Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg',
                          'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Label', 'Flow Byts/s', 'Flow Pkts/s'])

    return df


def save_predictions(predictions, output_path):
    # Convert predictions to a DataFrame
    predictions_df = pd.DataFrame({'Label': predictions})

    # Save predictions to a CSV file
    predictions_df.to_csv(output_path, index=False)
    print("Predictions saved to:", output_path)


def main():
    capture_duration = sys.argv[3]  # 20 seconds
    capture_output_file = sys.argv[1]
    output_directory = sys.argv[2]
    model_path = f"{output_directory}/../python/rf1_ids17_scaled.pkl"

    try:
        # Check if the capture file exists
        if os.path.exists(capture_output_file):

            a = (capture_output_file.split("\\")[-1]).split(".pcap")[0]
            # Process the flow CSV file
            flow_csv_path = f"{output_directory}\{a}.pcap_Flow.csv"
            df = process_flow_csv(flow_csv_path)

            # Load the pre-trained model
            with open(model_path, 'rb') as model_file:
                model = pickle.load(model_file)

            # Make predictions
            predictions = model.predict(df)

            # Save predictions
            predictions_output_path = f"{output_directory}/predictions.csv"
            save_predictions(predictions, predictions_output_path)
        else:
            print("Capture file does not exist.")

    except Exception as e:
        print("An error occurred:", e)


if __name__ == "__main__":
    main()
